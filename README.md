# ğŸ™ï¸ Goobits STT

A pure speech-to-text engine with multiple operation modes and advanced text formatting. Features real-time transcription, WebSocket server capabilities, and comprehensive text processing with internationalization support. Built on Whisper models for accurate transcription across various languages and use cases.

## ğŸ”— Related Projects

- **[Matilda](https://github.com/goobits/matilda)** - AI assistant
- **[Goobits STT](https://github.com/goobits/stt)** - Speech-to-Text engine (this project)
- **[Goobits TTS](https://github.com/goobits/tts)** - Text-to-Speech engine
- **[Goobits TTT](https://github.com/goobits/ttt)** - Text-to-Text processing

## ğŸ“‹ Table of Contents

- [Installation](#-installation)
- [Basic Usage](#-basic-usage)
- [Configuration](#ï¸-configuration)
- [Operation Modes](#-operation-modes)
- [Performance Optimization](#-performance-optimization)
- [Transcription Backends](#-transcription-backends)
- [Text Formatting Features](#-text-formatting-features)
- [Server Deployment](#-server-deployment)
- [Testing & Development](#-testing--development)
- [Model Comparison](#-model-comparison)
- [Audio Features](#ï¸-audio-features)
- [Tech Stack](#ï¸-tech-stack)

## ğŸ“¦ Installation

```bash
# Install globally with pipx (recommended)
pipx install .                     # Install globally, isolated environment
pipx install .[dev]               # Install with development dependencies

# Install with Apple Silicon optimization (macOS M1/M2/M3)
pipx install .[mac]               # Install with Parakeet MLX backend
pipx install .[mac,dev]           # Install with both mac and dev extras

# Or with pip for development
pip install -e .[dev]              # Install editable with dev dependencies
stt --version                      # Verify installation
stt --listen-once                  # Test basic functionality
```

## ğŸ¯ Basic Usage

```bash
stt --listen-once                  # Single utterance with VAD
stt --conversation                 # Always listening mode
stt --tap-to-talk=f8              # Tap F8 to start/stop recording
stt --hold-to-talk=space          # Hold spacebar to record
stt --server --port=8769          # Run WebSocket server
```

## âš™ï¸ Configuration

```bash
# Edit main configuration
nano config.json

# Configure Whisper model
stt --model large-v3-turbo --language en

# Audio settings
stt --device "USB Audio" --sample-rate 16000

# Output formats
stt --format json | jq -r '.text'
stt --format text --no-formatting
```

## ğŸ¤ Operation Modes

```bash
# Quick transcription
stt --listen-once | llm-process

# Interactive conversation
stt --conversation | tts-speak

# Hotkey control
stt --tap-to-talk=f8              # Toggle recording with F8
stt --hold-to-talk=ctrl+space     # Push-to-talk mode

# Server mode for remote clients
stt --server --host 0.0.0.0 --port 8769
```

## ğŸš€ Performance Optimization

```bash
# GPU acceleration (if available)
stt --model base --device cuda

# CPU optimization
stt --model tiny --device cpu

# Model selection by speed/quality
stt --model tiny      # Fastest, lower quality
stt --model base      # Balanced (default)
stt --model large-v3-turbo  # Best quality
```

## ğŸ”§ Transcription Backends

STT supports pluggable backends optimized for different platforms:

### faster_whisper (Default)
```bash
# Cross-platform backend with CUDA support
# Edit config.json:
{
  "transcription": {
    "backend": "faster_whisper"
  },
  "whisper": {
    "model": "base",
    "device": "auto",
    "compute_type": "auto"
  }
}
```

**Features:**
- âœ… Cross-platform (Linux, macOS, Windows)
- âœ… GPU acceleration (CUDA)
- âœ… All model sizes (tiny â†’ large-v3-turbo)
- âœ… Auto-detection of optimal compute type

### parakeet (Apple Silicon)
```bash
# Install MLX backend for macOS M1/M2/M3
pip install goobits-stt[mac]

# Edit config.json:
{
  "transcription": {
    "backend": "parakeet"
  },
  "parakeet": {
    "model": "mlx-community/parakeet-tdt-0.6b-v3"
  }
}
```

**Features:**
- âœ… Optimized for Apple Silicon (M1/M2/M3)
- âœ… Lower memory footprint
- âœ… Native Metal acceleration
- âš ï¸ macOS only (requires MLX support)

**Backend Selection:**
- **Use faster_whisper**: Cross-platform needs, CUDA GPU, larger models
- **Use parakeet**: Apple Silicon (M1/M2/M3), lower memory usage

## ğŸ­ Text Formatting Features

```bash
# Advanced entity detection
stt --listen-once  # "Call me at 555-123-4567" â†’ "Call me at (555) 123-4567"
stt --listen-once  # "Go to github dot com" â†’ "Go to github.com"
stt --listen-once  # "Three point one four" â†’ "3.14"

# Multilingual support
stt --language es  # Spanish formatting rules
stt --language en  # English formatting (default)

# Disable formatting
stt --no-formatting  # Raw transcription output
```

## ğŸ”§ Server Deployment

```bash
# Basic server
stt --server

# Production with SSL
stt --server --port 443 --host 0.0.0.0

# Docker deployment
docker run -p 8080:8080 -p 8769:8769 sttservice/transcribe
```

## ğŸ¯ Testing & Development

```bash
# Install test dependencies
pip install -e .[dev]              # Install dev dependencies
python -m spacy download en_core_web_sm  # Required for text formatting tests

# Run test suite
pytest                             # All tests
pytest tests/text_formatting/     # Specific module
pytest -v -n auto                 # Parallel with verbose output

# Code quality
ruff check src/ tests/             # Linting
black src/ tests/ stt.py          # Formatting
mypy src/ stt.py                  # Type checking

# Test with real audio
pytest tests/__fixtures__/audio/
```

## ğŸ”§ Model Comparison

| Model | Speed | Quality | Memory | Best For |
|-------|-------|---------|---------|----------|
| **tiny** | âš¡ Fastest | ğŸŒŸ Basic | ğŸ’¾ 39MB | Real-time, low resources |
| **base** | ğŸ”¥ Fast | ğŸŒŸğŸŒŸ Good | ğŸ’¾ 74MB | General use (default) |
| **small** | âš¡ Quick | ğŸŒŸğŸŒŸğŸŒŸ Better | ğŸ’¾ 244MB | Accuracy balance |
| **medium** | ğŸ”¥ Moderate | ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ Great | ğŸ’¾ 769MB | High accuracy |
| **large-v3-turbo** | ğŸ”¥ Fast | ğŸ† Best | ğŸ’¾ 1550MB | Production quality |

Choose based on your speed/accuracy requirements and available system resources.

## ğŸ™ï¸ Audio Features

- **Real-time streaming**: Opus audio encoding for efficient transmission
- **Voice Activity Detection**: Automatic speech detection and silence handling  
- **Multiple input devices**: Support for various microphones and audio interfaces
- **Hotkey integration**: System-wide keyboard shortcuts for hands-free operation
- **Background operation**: Run as daemon with minimal resource usage

## ğŸ› ï¸ Tech Stack

### Core Technologies
- **ğŸ§  AI/ML**: OpenAI Whisper (faster-whisper), CTranslate2, PyTorch
- **ğŸ Apple Silicon**: MLX, Parakeet (optional, macOS only)
- **ğŸ™ï¸ Audio**: OpusLib, NumPy, custom pipe-based audio capture
- **âŒ¨ï¸ System**: pynput for global hotkeys, cross-platform support

### Text Processing
- **ğŸ“ NLP**: spaCy, deepmultilingualpunctuation
- **ğŸŒ i18n**: Multi-language entity detection and formatting
- **ğŸ”§ Parsing**: pyparsing for complex text transformations
- **ğŸ“Š Output**: JSON/text formatting with rich entity support

### Development & Testing
- **ğŸ§ª Testing**: pytest with asyncio, xdist, custom plugins
- **ğŸ“Š Quality**: ruff (linting), black (formatting), mypy (typing)
- **ğŸ” Security**: bandit for security analysis
- **ğŸ“¦ Build**: setuptools, pyproject.toml configuration

### Deployment
- **ğŸ³ Containerization**: Docker with CUDA 12.1 support
- **ğŸ–¥ï¸ Interface**: FastAPI admin dashboard (Docker), responsive web UI
- **ğŸ”’ Security**: JWT authentication, RSA+AES encryption (Docker)
- **ğŸ“ˆ Monitoring**: Structured logging, health checks
- **â˜ï¸ Cloud**: Ready for production deployment with SSL/TLS